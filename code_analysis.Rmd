---
title: "Code Analysis"
author: "Lars Wenger"
date: "2024-03-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Import Libraries
```{r echo = T, results = 'hide'}
libraries = c( "fpp3", "ggplot2", "dplyr", "tidyr", "readxl", "forecast", "zoo", "tsibble", "GGally", "lubridate", "tidyverse", "stringi")

lapply(libraries, function(x) if (!(x %in% installed.packages())) {
  install.packages(x)
})

lapply(libraries, library, quietly = TRUE, character.only = TRUE)
```

# Read Data
```{r read_data}
rm(list=ls())

setwd("C:/Thesis")

data <- read_csv("Data/data.csv", locale = locale(encoding = "UTF-8"))
cluster_data <- read_csv("Data/data_withclusters.csv", locale = locale(encoding = "UTF-8"))
topic_model_data <- read_csv("Data/topicModel_description.csv", locale = locale(encoding = "UTF-8"))
vect_desc_data <- read_csv("Data/VectorizedText_description.csv", locale = locale(encoding = "UTF-8"))
vect_cause_data <- read_csv("Data/VectorizedText_cause.csv", locale = locale(encoding = "UTF-8"))
vect_clause_notes_data <- read_csv("Data/VectorizedText_close_notes.csv", locale = locale(encoding = "UTF-8"))
proportion_data <- read_csv("Data/data_proportion.csv", locale = locale(encoding = "UTF-8"))


#Merge all data by number
data_all <- data %>%
  inner_join(cluster_data, by = c("number" = "number")) %>%
  inner_join(topic_model_data, by = c("number" = "number")) %>%
  inner_join(vect_desc_data, by = c("number" = "number")) %>%
  inner_join(vect_cause_data, by = c("number" = "number")) %>%
  inner_join(vect_clause_notes_data, by = c("number" = "number")) %>%
  inner_join(proportion_data, by = c("number" = "number"))
```
```{r}
# Do a copy of data_all and replace "Unico" with FuBar
data_gpt <- data_all
data_gpt$created_by_group[data_gpt$created_by_group == "Unico"] <- "FuBar"
#Rplace the column account with a Substring of the last 3 letters
data_gpt$account <-  paste0(substr(data_gpt$account, 1, 2), substr(data_gpt$account, nchar(data_gpt$account)-3, nchar(data_gpt$account)))

#remove columns 17-19
data_gpt <- data_gpt[,-c(17:19)]

state_index <- grep("prop_state", colnames(data_all))
group_index <- grep("prop_group", colnames(data_all))
topic_index <- grep("topic_", colnames(data_all))

#Data Selection
data_gpt <- data_gpt %>% select(cluster, created_by_group, account, openedToClosed, time_worked, topic_index, state_index, group_index, case_cause, resolution_code, impact, priority, urgency)

#Save file without index
write.csv(data_gpt, "Data/data_gpt.csv", row.names = FALSE)
```

```{r}
data_all$cluster <- as.factor(data_all$cluster)
# Plot a Boxplot of each Cluster for openedToClosed and time_worked

ggplot(data_all, aes(x = cluster, y = data_all$openedToClosed)) + 
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribution of Opened to Closed Across Clusters", y = "Opened to Closed (Hours)", x = "Cluster")
```
```{r}
# Plot a ggplot bar Plot of Business Services for data_all cluster == 3, fill with data_prop_state. Show text in x axis in a 45 degree angle

# Histogram comparison
ggplot(data_all, aes(x = openedToClosed, fill = as.factor(cluster == c(7)))) +
  geom_histogram(alpha = 0.5, position = "identity", binwidth = 20) +
  scale_fill_manual(values = c("red", "blue"), labels = c("Other Clusters", "Cluster 7")) +
  labs(x = "Duration (openedToClosed)", y = "Frequency", title = "Comparison of Ticket Duration: Cluster 7 vs Other Clusters") +
  theme_minimal()
```

```{r}
# Select the columns that contains "prop_state" in the name
state_index <- grep("prop_state", colnames(data_all))
# Make new datafram with columns 1-6 and 20-25
data_prop_state <- select(data_all, number, cluster, c(state_index))

# Remove prop_state_ of column names
colnames(data_prop_state) <- gsub("prop_state_", "", colnames(data_prop_state))

# grouping the data by the cluster number, calculating the average duration for tickets within each cluster, and then visualizing these averages to identify any notable differences among the clusters.
data_prop_state %>%
  group_by(cluster) %>%
  summarise_all(mean) %>%
  pivot_longer(cols = c(3:length(data_prop_state)), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = cluster, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Duration of Tickets by Cluster",
       x = "Cluster",
       y = "Average Duration",
       fill = "Variable") +
  theme_minimal()
```

```{r}
# Select the columns that contains "prop_state" in the name
user_index <- grep("prop_user", colnames(data_all))

data_prop_user <- select(data_all, cluster, openedToClosed, c(user_index))

data_prop_user <- data_prop_user %>% filter(openedToClosed > 20)

# Remove openedToClosed column
data_prop_user <- data_prop_user[-2]

# Replace NA with 0
data_prop_user[is.na(data_prop_user)] <- 0

# Remove prop_user_ of column names
colnames(data_prop_user) <- gsub("prop_user_", "", colnames(data_prop_user))
# 
# Add row with the mean of the columns
colSum <- rbind(data_prop_user, colMeans(data_prop_user[-1]))

# Get all column indexes, where last row is > 2
index <- which(colSum[nrow(colSum),] > 2.5)

# usering the data by the cluster number, calculating the average duration for tickets within each cluster, and then visualizing these averages to identify any notable differences among the clusters.
data_prop_user %>%
  group_by(cluster) %>%
  select(cluster, index) %>%
  summarise_all(mean) %>%
  pivot_longer(cols = c(2:6), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = cluster, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Duration of Tickets by Cluster",
       x = "Cluster",
       y = "Average Duration",
       fill = "Variable") +
  theme_minimal()

```


```{r}
# Select the columns that contains "prop_state" in the name
group_index <- grep("prop_group", colnames(data_all))

data_prop_group <- select(data_all, cluster, openedToClosed, c(group_index))

data_prop_group <- data_prop_group %>% filter(openedToClosed > 20 & prop_group_Service.Desk.1st.Level < 95)

# Remove openedToClosed column
data_prop_group <- data_prop_group[-2]

# # Replace NA with 0
# data_prop_group[is.na(data_prop_group)] <- 0
# 
# # Remove prop_group_ of column names
# colnames(data_prop_group) <- gsub("prop_group_", "", colnames(data_prop_group))
# 
# # Add row with the mean of the columns
# colSum <- rbind(data_prop_group, colMeans(data_prop_group[-1]))
# 
# # Get all column indexes, where last row is > 2
# index <- which(colSum[nrow(colSum),] > 2)

# grouping the data by the cluster number, calculating the average duration for tickets within each cluster, and then visualizing these averages to identify any notable differences among the clusters.
data_prop_group %>%
  group_by(cluster) %>%
  summarise_all(mean) %>%
  pivot_longer(cols = c(2:length(data_prop_group)), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = cluster, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Duration of Tickets by Cluster",
       x = "Cluster",
       y = "Average Duration",
       fill = "Variable") +
  theme_minimal()
```

## Focus on Topics

```{r}
# Reshape from wide to long format and create a new 'term_type' column
data_long <- data_all %>%
  pivot_longer(
    cols = c(topic_index),
    names_to = c("topic"),
    values_to = "value"
  )


mytopic = "topic_network_server"

# Convert date column to Date type if not already
data_long$date <- as.Date(data_long$opened)

# Define the date cutoff for the last 3 months
end_date <- max(data_long$date)  # assuming you want up to the latest date in your dataset
start_date <- end_date %m-% months(3)  # 3 months before the end date

# Filter data for the last 3 months and the period before it
recent_data <- data_long %>%
  filter(date > start_date) %>%
  filter(cluster == c(1:6))

previous_data <- data_long %>%
  filter(date <= start_date & date > (start_date %m-% months(3)))%>%
  filter(cluster == c(1:6))

# Calculate average TF-IDF scores
avg_recent <- recent_data %>%
  filter(cluster == c(1:6)) %>%
  group_by(topic) %>%
  summarise(avg_tf_idf_recent = mean(value))

avg_previous <- previous_data %>%
  filter(cluster == c(1:6)) %>%
  group_by(topic) %>%
  summarise(avg_tf_idf_previous = mean(value))

# Merge the two datasets
trend_analysis <- merge(avg_recent, avg_previous, by = "topic")

# Calculate the difference in TF-IDF scores
trend_analysis <- trend_analysis %>%
  mutate(change_in_tf_idf = avg_tf_idf_recent - avg_tf_idf_previous)

# Identify top 5 terms with increased TF-IDF scores
top_increased <- trend_analysis %>%
  arrange(desc(change_in_tf_idf)) %>%
  head(5)

# Identify top 5 terms with decreased TF-IDF scores
top_decreased <- trend_analysis %>%
  arrange(change_in_tf_idf) %>%
  head(5)


print("Top 5 increased terms in the last 3 months:")
print(top_increased)

print("Top 5 decreased terms in the last 3 months:")
print(top_decreased)


# Assuming you're interested in a specific term across dates
filtered_data <- data_long %>% 
  # filter(term == myterm & term_type == myterm_type)
  filter(topic == mytopic)

# Add categorical columns of openedToClosed breaking by 25%, 50%, 75% and 100%
filtered_data$openedToClosed_cat <- cut(filtered_data$openedToClosed, breaks = quantile(filtered_data$openedToClosed, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE), include.lowest = TRUE)


# Add a trendline for each cluster

ggplot(filtered_data, aes(x = opened, y = value, color = openedToClosed_cat)) +
  geom_smooth(method = "lm") +
  labs(x = "Date (Opened)", y = "TF-IDF Score", title = paste("Trend of", mytopic, "Over Time")) +
  theme_minimal()
```

```{r}
# For each cluster and topic, calculate the average TF-IDF score
avg_tf_idf <- data_long %>%
  group_by(cluster, topic) %>%
  summarise(avg_tf_idf = mean(value))

# Plot the average TF-IDF scores for each cluster and topic
ggplot(avg_tf_idf, aes(x = cluster, y = avg_tf_idf, fill = topic)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average TF-IDF Scores by Cluster and Topic",
       x = "Cluster",
       y = "Average TF-IDF Score",
       fill = "Topic") +
  theme_minimal()

# For a specific cluster and topic, plot the trend of TF-IDF scores over time
mycluster <- c(7)

filtered_data <- data_long %>%
  filter(cluster == mycluster, topic == mytopic)

ggplot(filtered_data, aes(x = opened, y = value)) +
  geom_line() +
  geom_smooth(method = "lm") +
  labs(title = paste("Trend of", mytopic, "for Cluster", mycluster),
       x = "Date (Opened)",
       y = "TF-IDF Score") +
  theme_minimal()
```
```{r}
topic_index <- grep("topic_", colnames(data_all))

# Calculate the mean of the topic columns grouped by 'cluster'
topic_distribution_by_cluster <- data_all %>%
  select(cluster, all_of(topic_index)) %>%
  group_by(cluster) %>%
  summarise(across(everything(), mean, na.rm = TRUE))

# Reshape the data for plotting
long_topic_distribution <- pivot_longer(topic_distribution_by_cluster, 
                                        cols = -cluster, 
                                        names_to = "Topic", 
                                        values_to = "Mean_Frequency")

# Plotting with ggplot2
ggplot(long_topic_distribution, aes(x = Topic, y = Mean_Frequency, group = cluster, color = factor(cluster))) +
  geom_line() +
  geom_point() + # Add points to the line plot
  theme_minimal() +
  labs(title = 'Mean Frequency of Topics Across Clusters',
       x = 'Topic', y = 'Mean Frequency',
       color = 'Cluster') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + # Rotate x-axis labels for better readability
  scale_color_brewer(palette = "Set1")  # Use a color palette that's clear

```
```{r}
library(corrplot)

numeric_data <- select(data_all, openedToClosed, topic_index, group_index, state_index, user_index)

# Calculate correlation matrix
correlation_matrix <- cor(numeric_data, use = "complete.obs")

# Extract correlations with 'openedToClosed'
correlation_with_openedToClosed <- correlation_matrix["openedToClosed", ]

# Sort and select the top 5 and bottom 5 correlations
top_bottom_correlation <- sort(correlation_with_openedToClosed, decreasing = TRUE)
top_3 <- head(top_bottom_correlation, 5)
bottom_3 <- tail(top_bottom_correlation, 4)

# Combine top 5 and bottom 5 for visualization
important_correlations <- c(top_3, bottom_3)
important_correlation_values <- correlation_matrix[rownames(correlation_matrix) %in% names(important_correlations), 
                                                   colnames(correlation_matrix) %in% names(important_correlations)]


# Plotting the selected correlations
corrplot(important_correlation_values, method = "circle", type = "upper",
         tl.col = "black", tl.srt = 45)  # Rotate labels for better readability

```




