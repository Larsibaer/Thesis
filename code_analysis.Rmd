---
title: "Code Analysis"
author: "Lars Wenger"
date: "2024-03-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Import Libraries
```{r echo = T, results = 'hide'}
libraries = c( "fpp3", "ggplot2", "dplyr", "tidyr", "readxl", "forecast", "zoo", "tsibble", "GGally", "lubridate", "tidyverse", "stringi")

lapply(libraries, function(x) if (!(x %in% installed.packages())) {
  install.packages(x)
})

lapply(libraries, library, quietly = TRUE, character.only = TRUE)
```

# Read Data
```{r read_data}
rm(list=ls())

setwd("C:/Thesis")

data <- read_csv("Data/data.csv", locale = locale(encoding = "UTF-8"))
cluster_data <- read_csv("Data/data_withclusters.csv", locale = locale(encoding = "UTF-8"))
topic_model_data <- read_csv("Data/topicModel_description.csv", locale = locale(encoding = "UTF-8"))
vect_desc_data <- read_csv("Data/VectorizedText_description.csv", locale = locale(encoding = "UTF-8"))
vect_cause_data <- read_csv("Data/VectorizedText_cause.csv", locale = locale(encoding = "UTF-8"))
vect_clause_notes_data <- read_csv("Data/VectorizedText_close_notes.csv", locale = locale(encoding = "UTF-8"))
proportion_data <- read_csv("Data/data_proportion.csv", locale = locale(encoding = "UTF-8"))


#Merge all data by number
data_all <- data %>%
  inner_join(cluster_data, by = c("number" = "number")) %>%
  inner_join(topic_model_data, by = c("number" = "number")) %>%
  inner_join(vect_desc_data, by = c("number" = "number")) %>%
  inner_join(vect_cause_data, by = c("number" = "number")) %>%
  inner_join(vect_clause_notes_data, by = c("number" = "number")) %>%
  inner_join(proportion_data, by = c("number" = "number"))
```
```{r}
# Do a copy of data_all and replace "Unico" with FuBar
data_gpt <- data_all
data_gpt$created_by_group[data_gpt$created_by_group == "Unico"] <- "FuBar"
#Rplace the column account with a Substring of the last 3 letters
data_gpt$account <-  paste0(substr(data_gpt$account, 1, 2), substr(data_gpt$account, nchar(data_gpt$account)-3, nchar(data_gpt$account)))

#remove columns 17-19
data_gpt <- data_gpt[,-c(17:19)]

#Save file without index
write.csv(data_gpt, "Data/data_gpt.csv", row.names = FALSE)
```

```{r}
data_all$cluster <- as.factor(data_all$cluster)
# Plot a Boxplot of each Cluster for openedToClosed and time_worked
ggplot(data_all, aes(x = cluster, y = data_all$openedToClosed)) + 
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribution of Opened to Closed Across Clusters", y = "Opened to Closed (Hours)", x = "Cluster")
```
```{r}
# Plot a ggplot bar Plot of Business Services for data_all cluster == 3, fill with data_prop_state. Show text in x axis in a 45 degree angle

# Histogram comparison
ggplot(data_all, aes(x = openedToClosed, fill = as.factor(cluster == c(4,5)))) +
  geom_histogram(alpha = 0.5, position = "identity", binwidth = 20) +
  scale_fill_manual(values = c("red", "blue"), labels = c("Other Clusters", "Cluster 4 or 5")) +
  labs(x = "Duration (openedToClosed)", y = "Frequency", title = "Comparison of Ticket Duration: Cluster 3 vs Other Clusters") +
  theme_minimal()
```

```{r}
# Select the columns that contains "prop_state" in the name
state_index <- grep("prop_state", colnames(data_all))
# Make new datafram with columns 1-6 and 20-25
data_prop_state <- select(data_all, number, cluster, c(state_index))

# Remove prop_state_ of column names
colnames(data_prop_state) <- gsub("prop_state_", "", colnames(data_prop_state))

# grouping the data by the cluster number, calculating the average duration for tickets within each cluster, and then visualizing these averages to identify any notable differences among the clusters.
data_prop_state %>%
  group_by(cluster) %>%
  summarise_all(mean) %>%
  pivot_longer(cols = c(3:length(data_prop_state)), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = cluster, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Duration of Tickets by Cluster",
       x = "Cluster",
       y = "Average Duration",
       fill = "Variable") +
  theme_minimal()
```

```{r}
# Select the columns that contains "prop_state" in the name
user_index <- grep("prop_user", colnames(data_all))

data_prop_user <- select(data_all, cluster, c(user_index))

# Replace NA with 0
data_prop_user[is.na(data_prop_user)] <- 0

# Remove prop_user_ of column names
colnames(data_prop_user) <- gsub("prop_user_", "", colnames(data_prop_user))

# Add row with the mean of the columns
colSum <- rbind(data_prop_user, colMeans(data_prop_user[-1]))

# Get all column indexes, where last row is > 2
index <- which(colSum[nrow(colSum),] > 3)

# usering the data by the cluster number, calculating the average duration for tickets within each cluster, and then visualizing these averages to identify any notable differences among the clusters.
data_prop_user %>%
  select(cluster, index) %>%
  group_by(cluster) %>%
  summarise_all(mean) %>%
  pivot_longer(cols = c(2:length(index)), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = cluster, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Duration of Tickets by Cluster",
       x = "Cluster",
       y = "Average Duration",
       fill = "Variable") +
  theme_minimal()

```


```{r}
# Select the columns that contains "prop_state" in the name
group_index <- grep("prop_group", colnames(data_all))

data_prop_group <- select(data_all, cluster, c(group_index))

# Replace NA with 0
data_prop_group[is.na(data_prop_group)] <- 0

# Remove prop_group_ of column names
colnames(data_prop_group) <- gsub("prop_group_", "", colnames(data_prop_group))

# Add row with the mean of the columns
colSum <- rbind(data_prop_group, colMeans(data_prop_group[-1]))

# Get all column indexes, where last row is > 2
index <- which(colSum[nrow(colSum),] > 2)

# grouping the data by the cluster number, calculating the average duration for tickets within each cluster, and then visualizing these averages to identify any notable differences among the clusters.
data_prop_group %>%
  select(cluster, index) %>%
  group_by(cluster) %>%
  summarise_all(mean) %>%
  pivot_longer(cols = c(2:length(index)), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = cluster, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Duration of Tickets by Cluster",
       x = "Cluster",
       y = "Average Duration",
       fill = "Variable") +
  theme_minimal()

data_prop_group %>%
  select(cluster, index) %>%
  filter(cluster %in% c(4,5)) %>%
  group_by(cluster) %>%
  summarise_all(mean) %>%
  pivot_longer(cols = c(2:length(index)), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = cluster, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Duration of Tickets by Cluster 4 and 5",
       x = "Cluster",
       y = "Average Duration",
       fill = "Variable") +
  theme_minimal()

test <- data_prop_group %>%
  group_by(cluster) %>%
  summarise_all(mean)

data_long_group <- data_all %>%
  select(opened, group_index) %>%
  select(opened, index) %>%
  pivot_longer(cols = -opened, names_to = "group", values_to = "value")

# Plotting the timeline
ggplot(data_long_group, aes(x = opened, y = value, color = group)) +
  geom_line(alpha = 0.2) +
  geom_smooth(method = "lm") +
  labs(title = "Timeline of Prop Group Values", x = "Time", y = "Value") +
  theme_minimal() +
  theme(legend.position = "bottom")


```

## Focus on Topics

```{r}
# Reshape from wide to long format and create a new 'term_type' column
data_long <- data_all %>%
  pivot_longer(
    cols = c(21:26),
    names_to = c("topic"),
    values_to = "value"
  )


mytopic = "VDI_Troubleshooting"

# Convert date column to Date type if not already
data_long$date <- as.Date(data_long$opened)

# Define the date cutoff for the last 3 months
end_date <- max(data_long$date)  # assuming you want up to the latest date in your dataset
start_date <- end_date %m-% months(3)  # 3 months before the end date

# Filter data for the last 3 months and the period before it
recent_data <- data_long %>%
  filter(date > start_date) %>%
  filter(cluster == c(4,5))

previous_data <- data_long %>%
  filter(date <= start_date & date > (start_date %m-% months(3)))%>%
  filter(cluster == c(4,5))

# Calculate average TF-IDF scores
avg_recent <- recent_data %>%
  filter(cluster == c(4,5)) %>%
  group_by(topic) %>%
  summarise(avg_tf_idf_recent = mean(value))

avg_previous <- previous_data %>%
  filter(cluster == c(4,5)) %>%
  group_by(topic) %>%
  summarise(avg_tf_idf_previous = mean(value))

# Merge the two datasets
trend_analysis <- merge(avg_recent, avg_previous, by = "topic")

# Calculate the difference in TF-IDF scores
trend_analysis <- trend_analysis %>%
  mutate(change_in_tf_idf = avg_tf_idf_recent - avg_tf_idf_previous)

# Identify top 5 terms with increased TF-IDF scores
top_increased <- trend_analysis %>%
  arrange(desc(change_in_tf_idf)) %>%
  head(5)

# Identify top 5 terms with decreased TF-IDF scores
top_decreased <- trend_analysis %>%
  arrange(change_in_tf_idf) %>%
  head(5)


print("Top 5 increased terms in the last 3 months:")
print(top_increased)

print("Top 5 decreased terms in the last 3 months:")
print(top_decreased)


# Assuming you're interested in a specific term across dates
filtered_data <- data_long %>% 
  # filter(term == myterm & term_type == myterm_type)
  filter(topic == mytopic)

# Add a trendline for each cluster

ggplot(filtered_data, aes(x = opened, y = value, color = cluster)) +
  geom_line(alpha = 0.6) +
  geom_smooth(method = "lm") +
  labs(x = "Date (Opened)", y = "TF-IDF Score", title = paste("Trend of", mytopic, "Over Time")) +
  theme_minimal()
```

```{r}

```



