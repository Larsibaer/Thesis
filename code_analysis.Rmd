---
title: "Code Analysis"
author: "Lars Wenger"
date: "2024-03-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Import Libraries
```{r echo = T, results = 'hide'}
libraries = c( "fpp3", "ggplot2", "dplyr", "tidyr", "readxl", "forecast", "zoo", "tsibble", "GGally", "lubridate", "tidyverse", "stringi")

lapply(libraries, function(x) if (!(x %in% installed.packages())) {
  install.packages(x)
})

lapply(libraries, library, quietly = TRUE, character.only = TRUE)
```

# Read Data
```{r read_data}
rm(list=ls())

setwd("C:/Thesis")

data <- read_csv("Data/data.csv", locale = locale(encoding = "UTF-8"))
cluster_data <- read_csv("Data/data_withclusters.csv", locale = locale(encoding = "UTF-8"))
topic_model_data <- read_csv("Data/topicModel_description.csv", locale = locale(encoding = "UTF-8"))
vect_desc_data <- read_csv("Data/VectorizedText_description.csv", locale = locale(encoding = "UTF-8"))
vect_cause_data <- read_csv("Data/VectorizedText_cause.csv", locale = locale(encoding = "UTF-8"))
vect_clause_notes_data <- read_csv("Data/VectorizedText_close_notes.csv", locale = locale(encoding = "UTF-8"))
proportion_data <- read_csv("Data/data_proportion.csv", locale = locale(encoding = "UTF-8"))


#Merge all data by number
data_all <- data %>%
  inner_join(cluster_data, by = c("number" = "number")) %>%
  inner_join(topic_model_data, by = c("number" = "number")) %>%
  inner_join(vect_desc_data, by = c("number" = "number")) %>%
  inner_join(vect_cause_data, by = c("number" = "number")) %>%
  inner_join(vect_clause_notes_data, by = c("number" = "number")) %>%
  inner_join(proportion_data, by = c("number" = "number"))
```
```{r}
# Do a copy of data_all and replace "Unico" with FuBar
data_gpt <- data_all
data_gpt$created_by_group[data_gpt$created_by_group == "Unico"] <- "FuBar"
#Rplace the column account with a Substring of the last 3 letters
data_gpt$account <-  paste0(substr(data_gpt$account, 1, 2), substr(data_gpt$account, nchar(data_gpt$account)-3, nchar(data_gpt$account)))

#remove columns 17-19
data_gpt <- data_gpt[,-c(17:19)]

#Save file without index
write.csv(data_gpt, "Data/data_gpt.csv", row.names = FALSE)
```

```{r}
# Generate new df with 10 random observation of data_all
data_sample <- data_all[sample(1:nrow(data_all), 10),]
```

```{r}
con<-file('Data/data_all.csv',encoding="UTF-8")
#save data_all as csv
write.csv(data_all, file = con)
```
```{r}
data_all$cluster <- as.factor(data_all$cluster)
# Plot a Boxplot of each Cluster for openedToClosed and time_worked
ggplot(data_all, aes(x = cluster, y = data_all$openedToClosed)) + 
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribution of Opened to Closed Across Clusters", y = "Opened to Closed (Hours)", x = "Cluster")

data_all$cluster <- as.factor(data_all$cluster)
# Plot a Boxplot of each Cluster for openedToClosed and time_worked
ggplot(data_all, aes(x = cluster, y = data_all$time_worked)) + 
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribution of Time Worked Across Clusters", y = "Time Worked (Hours)", x = "Cluster")
```
```{r}
# Plot a ggplot bar Plot of Business Services for data_all cluster == 3, fill with data_prop_state. Show text in x axis in a 45 degree angle

# Histogram comparison
ggplot(data_all, aes(x = openedToClosed, fill = as.factor(cluster == c(1,5)))) +
  geom_histogram(alpha = 0.5, position = "identity", binwidth = 20) +
  scale_fill_manual(values = c("red", "blue"), labels = c("Other Clusters", "Cluster 1 or 5")) +
  labs(x = "Duration (openedToClosed)", y = "Frequency", title = "Comparison of Ticket Duration: Cluster 3 vs Other Clusters") +
  theme_minimal()
```

```{r}
# Select the columns that contains "prop_state" in the name
state_index <- grep("prop_state", colnames(data_all))
# Make new datafram with columns 1-6 and 20-25
data_prop_state <- select(data_all, number, cluster, c(state_index))

# Remove prop_state_ of column names
colnames(data_prop_state) <- gsub("prop_state_", "", colnames(data_prop_state))

# grouping the data by the cluster number, calculating the average duration for tickets within each cluster, and then visualizing these averages to identify any notable differences among the clusters.
data_prop_state %>%
  group_by(cluster) %>%
  summarise_all(mean) %>%
  pivot_longer(cols = c(3:length(data_prop_state)), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = cluster, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Duration of Tickets by Cluster",
       x = "Cluster",
       y = "Average Duration",
       fill = "Variable") +
  theme_minimal()
```

```{r}
# Select the columns that contains "prop_state" in the name
user_index <- grep("prop_user", colnames(data_all))

data_prop_user <- select(data_all, number, cluster, c(user_index))

# Replace NA with 0
data_prop_user[is.na(data_prop_user)] <- 0

# get length of data_prop_user
length(data_prop_user)


# usering the data by the cluster number, calculating the average duration for tickets within each cluster, and then visualizing these averages to identify any notable differences among the clusters.
data_prop_user %>%
  group_by(cluster) %>%
  summarise_all(mean) %>%
  pivot_longer(cols = c(3:length(data_prop_user)), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = cluster, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Duration of Tickets by Cluster",
       x = "Cluster",
       y = "Average Duration",
       fill = "Variable") +
  theme_minimal()

# Plot barplot and legend separetly
data_prop_user %>%
  group_by(cluster) %>%
  summarise_all(mean) %>%
  pivot_longer(cols = c(3:length(data_prop_user)), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = cluster, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Duration of Tickets by Cluster",
       x = "Cluster",
       y = "Average Duration",
       fill = "Variable") +
  theme_minimal() +
  theme(legend.position = "none")
```


```{r}
# Select the columns that contains "prop_state" in the name
group_index <- grep("prop_group", colnames(data_all))

data_prop_group <- select(data_all, number, cluster, c(group_index))

# Replace NA with 0
data_prop_group[is.na(data_prop_group)] <- 0

# Remove prop_group_ of column names
colnames(data_prop_group) <- gsub("prop_group_", "", colnames(data_prop_group))


# grouping the data by the cluster number, calculating the average duration for tickets within each cluster, and then visualizing these averages to identify any notable differences among the clusters.
data_prop_group %>%
  group_by(cluster) %>%
  summarise_all(mean) %>%
  pivot_longer(cols = c(3:length(data_prop_group)), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = cluster, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Duration of Tickets by Cluster",
       x = "Cluster",
       y = "Average Duration",
       fill = "Variable") +
  theme_minimal()
```



```{r}
# Business service distribution comparison
cluster_1Or5_services <- data_all %>% filter(cluster == c(1,5)) %>% count(business_service)
other_clusters_services <- data_all %>% filter(cluster != c(1,5)) %>% count(business_service)

# Plotting
ggplot() +
  geom_bar(data = cluster_1Or5_services, aes(x = business_service, y = n, fill = "Cluster 1 or 5"), stat = "identity", position = "dodge") +
  geom_bar(data = other_clusters_services, aes(x = business_service, y = n, fill = "Other Clusters"), stat = "identity", position = "dodge", alpha = 0.7) +
  scale_fill_manual(values = c("Cluster 3" = "blue", "Other Clusters" = "red")) +
  labs(x = "Business Service", y = "Count", title = "Business Service Distribution by Cluster") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
## Focus on tf-idf

```{r}
group_index <- grep("prop_group_", colnames(data_all))
# Make new Column of most responsle group. Look in the columns of group_index, if there is a value > 50, then assign the column name to the new column, else assign "Other"
data_all$most_responsible_group <- apply(data_all[group_index], 1, function(x) {
  ifelse(max(x, na.rm = TRUE) > 50, names(x)[which.max(x)], "Other")
})

description_index <- grep("description_", colnames(data_all))
cause_index <- grep("cause_", colnames(data_all))
close_notes_index <- grep("close_notes_", colnames(data_all))

# Remove prop_group_ of column names
colnames(data_all) <- gsub("close_notes_", "close_", colnames(data_all))

# Reshape from wide to long format and create a new 'term_type' column
data_long <- data_all %>%
  pivot_longer(
    cols = c(description_index, cause_index, close_notes_index),
    names_to = c("term_type", "term"),
    names_sep = "_",  # Split column names at underscores
    values_to = "tf_idf"
  )



data_long <- data_long %>% filter(tf_idf > 0)  # Remove rows with 0 values
```
```{r}
# Calculate the average TF-IDF for each word in each group and number of occurencies of this word
word_group_avgs <- data_long %>%
  group_by(term, most_responsible_group) %>%
  summarise(
    mean_duration = mean(openedToClosed, na.rm = TRUE),
    count = n(),  # Counting occurrences of each term
    .groups = 'drop'
  )

# Remove rows with count <100
word_group_avgs <- word_group_avgs %>% filter(count >= 100)

# Aggregate data to find dominant groups for each term
term_group_stats <- data_long %>%
  group_by(term, most_responsible_group) %>%
  summarise(mean_tf_idf = mean(tf_idf, na.rm = TRUE), .groups = 'drop') %>%
  arrange(desc(mean_tf_idf))

# Identify the top group for each term
top_groups_by_term <- term_group_stats %>%
  slice_max(order_by = mean_tf_idf, n = 1, with_ties = FALSE)

# Calculate the mean "openedToClosed" duration for these tickets
mean_durations <- top_words_joined %>%
  group_by(most_responsible_group, term) %>%
  summarise(mean_duration = mean(openedToClosed, na.rm = TRUE))

# Merge the top groups by term with their mean durations and count of occurrences
final_analysis <- merge(top_groups_by_term, mean_duration_by_term_group, by = c("term", "most_responsible_group"))

# Select relevant columns and potentially filter for the top terms or specific analysis
final_analysis <- final_analysis %>%
  select(term, group, mean_tf_idf, mean_duration, count)


# Plot mean duration for tickets containing top words by group
ggplot(final_analysis, aes(x = reorder(term, -mean_duration), y = mean_duration, fill = most_responsible_group)) +
  geom_bar(stat = "identity", position = position_dodge(), width = 0.7) +
  geom_text(aes(label = count), vjust = -0.5, position = position_dodge(width = 0.7)) +
  labs(x = "Term", y = "Mean Duration (openedToClosed)", title = "Mean Ticket Duration by Term and Group") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
```{r}
myterm = "outlook"
myterm_type = "close"

# Convert date column to Date type if not already
data_long$date <- as.Date(data_long$opened)

# Define the date cutoff for the last 3 months
end_date <- max(data_long$date)  # assuming you want up to the latest date in your dataset
start_date <- end_date %m-% months(3)  # 3 months before the end date

# Filter data for the last 3 months and the period before it
recent_data <- data_long %>%
  filter(date > start_date) %>%
  filter(cluster == 3)

previous_data <- data_long %>%
  filter(date <= start_date & date > (start_date %m-% months(3)))%>%
  filter(cluster == 3)

# Calculate average TF-IDF scores
avg_recent <- recent_data %>%
  filter(cluster == 3) %>%
  group_by(term) %>%
  summarise(avg_tf_idf_recent = mean(tf_idf))

avg_previous <- previous_data %>%
  filter(cluster == 3) %>%
  group_by(term) %>%
  summarise(avg_tf_idf_previous = mean(tf_idf))

# Merge the two datasets
trend_analysis <- merge(avg_recent, avg_previous, by = "term")

```

```{r}
# Calculate the difference in TF-IDF scores
trend_analysis <- trend_analysis %>%
  mutate(change_in_tf_idf = avg_tf_idf_recent - avg_tf_idf_previous)

# Identify top 5 terms with increased TF-IDF scores
top_increased <- trend_analysis %>%
  arrange(desc(change_in_tf_idf)) %>%
  head(5)

# Identify top 5 terms with decreased TF-IDF scores
top_decreased <- trend_analysis %>%
  arrange(change_in_tf_idf) %>%
  head(5)

```

```{r}
print("Top 5 increased terms in the last 3 months:")
print(top_increased)

print("Top 5 decreased terms in the last 3 months:")
print(top_decreased)

```

```{r}
# Assuming you're interested in a specific term across dates
filtered_data <- data_long %>% 
  # filter(term == myterm & term_type == myterm_type)
  filter(term == myterm)

# Add a trendline for each cluster

ggplot(filtered_data, aes(x = opened, y = tf_idf, color = cluster)) +
  geom_line(alpha = 0.4) +
  geom_smooth(method = "lm") +
  labs(x = "Date (Opened)", y = "TF-IDF Score", title = paste("Trend of", myterm, "in", myterm_type, "Over Time")) +
  theme_minimal()
```
```{r}
# Identify all columns that relate to group involvement, which are prefixed with 'prop_group_'
library(corrplot)
group_columns <- grep("prop_group_", names(data_all), value = TRUE)

clusters_1_5 <- data_all %>%
  filter(cluster %in% c(1, 5))

selected_data <- data_all %>% 
  filter(cluster %in% c(1, 5)) %>%
  select(openedToClosed, group_columns)

# Calculate the correlation matrix
correlation_matrix <- cor(selected_data, use = "complete.obs")

corrplot(correlation_matrix, method = "color", type = "upper", order = "hclust",
         tl.col = "black", tl.srt = 45)


# Show How the columns are influencing the openedToClosed duration
correlation_with_opened_to_closed <- cor(selected_data)
correlation_with_opened_to_closed <- correlation_with_opened_to_closed["openedToClosed", -1]
correlation_with_opened_to_closed




```

The prominent involvement of Service Desk 1st Level suggests that many issues in clusters 1 and 5 are handled at the first point of contact, which aligns with their potentially urgent or critical nature. The involvement of IT Operations and Cyber Security & Network groups in some cases might indicate technical complexities or security-related issues within these clusters.

```{r}
# Calculate the correlation between 'openedToClosed' and the group involvement columns
correlation_with_opened_to_closed <- cor(clusters_1_5[, c("openedToClosed", group_columns)])

# Extract the correlations of 'openedToClosed' with group columns
correlation_with_opened_to_closed <- correlation_with_opened_to_closed["openedToClosed", -1]

# Print the correlation results
correlation_with_opened_to_closed
library(corrplot)
correlation_matrix <- cor(clusters_1_5[, c("openedToClosed", group_columns)])
corrplot(correlation_matrix, method = "circle", type = "upper", order = "hclust",
         tl.col = "black", tl.srt = 45, # Rotate labels for better readability
         title = "Correlation between OpenedToClosed and Group Involvement Columns")
```
