---
title: "Thesis"
author: "Lars Wenger"
date: "2024-02-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r install}
# We start by installing the necessary libraries. Make sure to uncomment and run
# only the libraries which you haven't installed already. 
#install.packages("DescTools")
#install.packages("xgboost")
#install.packages("caret")
#install.packages("dplyr")
#install.packages("tidyverse")
#install.packages("mltools")
#install.packages("reshape2")
#install.packages("data.table")
#install.packages("pracma")
#install.packages("rsample")
# install.packages("PRROC")
# install.packages("e1071")
# install.packages("dlookr")
# install.packages("pROC")
# install.packages("ROCR")
# install.packages("nnet")
```
```{r libraries}
library(DescTools)
library(xgboost)
library(caret)
library(dplyr)
library(tidyverse)
library(mltools)
library(reshape2)
library(data.table)
library(pracma)
library(rsample)
library(PRROC)
library(e1071)
library(dlookr)
library(pROC)
library(ROCR)
library(nnet)
library(ggplot2)
options(scipen=999)
```


```{r import}
## Import data
# We set the working directory and we call the data that we are going to use. Please import the csv file.
rm(list=ls())

set.seed(7)

setwd("C:/Thesis")
#read json file
cases_data <- read_csv("Data/sn_customerservice_case_utf8.csv", locale = locale(encoding = "UTF-8"))
data <- cases_data # We make a copy from the original dataset and work on the copy

```
```{r strucutre}
data <- select(cases_data, number = number, case = case, description = description, case_type = u_case_type, due_date = due_date, first_response_time = first_response_time, closed = closed_at, opened = opened_at, account = account, contact = contact, created_by = sys_created_by, business_service = business_service, business_service_activity = u_business_service_activity, assigned_to = assigned_to, assignment_group = assignment_group, auto_close = auto_close, time_worked = time_worked, reassignment_count = reassignment_count, impact = impact, priority = priority, urgency = urgency, escalation = escalation, comments = comments, case_cause = u_case_cause, cause = cause, close_notes = close_notes, resolution_code = resolution_code, problem = problem)

```

```{r data}
# Filter between dates and removing rows who are not closed
data <- data %>% 
  filter(Year(strptime(data$opened, "%d-%m-%Y %H:%M:%S", tz="UTC")) <= Year("2024-02-01")) %>%
  filter(Year(strptime(data$opened, "%d-%m-%Y %H:%M:%S", tz="UTC")) >= Year("2020-01-01")) %>%
  filter(!is.na(closed))
```
```{r merging-sla}
# merg data sets
sla_data_clean <- read_csv("Data/task_sla.csv")

# Remove all rows, where sla_dataÂ£status is Cancelled
# sla_data <- sla_data %>% 
#   filter(stage != "Cancelled")


# Merge data and sla_data, where the number and closed of data is the same as task and stop time of sla_data

sla_data <- select(sla_data_clean, task = task, business_percentage = business_percentage, sla_has_breached = has_breached, duration = duration, end_time = end_time)

#remove duplicates of sla_data$task
sla_data <- sla_data %>% 
  distinct(task, .keep_all = TRUE)

data <- merge(x = data, y = sla_data, 
                     by.x = c("number", "closed"), 
                     by.y = c("task", "end_time"), 
                     all.x = TRUE)

```
```{r type}
# Transforming the type of the variables
data$opened <- as.POSIXct(strptime(data$opened, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data$closed <- as.POSIXct(strptime(data$closed, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data$due_date <- as.POSIXct(strptime(data$due_date, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data$first_response_time <- as.POSIXct(strptime(data$first_response_time, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data$auto_close <- as.factor(data$auto_close)
data$business_percentage <- as.numeric(data$business_percentage)
data$sla_has_breached <- as.factor(data$sla_has_breached)
data$reassignment_count <- as.numeric(data$reassignment_count)
data$impact <- as.factor(data$impact)
data$priority <- as.factor(data$priority)
data$urgency <- as.factor(data$urgency)
data$escalation <- as.factor(data$escalation)
data$case_cause <- as.factor(data$case_cause)
data$resolution_code <- as.factor(data$resolution_code)
data$problem <- as.factor(data$problem)
data$assignment_group <- as.factor(data$assignment_group)
data$assigned_to <- as.factor(data$assigned_to)
data$created_by <- as.factor(data$created_by)
data$business_service <- as.factor(data$business_service)
data$business_service_activity <- as.factor(data$business_service_activity)
data$case_type <- as.factor(data$case_type)
data$account <- as.factor(data$account)
data$contact <- as.factor(data$contact)
data$openedToClosed <- as.numeric(difftime(data$closed, data$opened, units = "hours"))
# add column created by cleaned. When cretad_by is admin, then it is system, when created_by ends witch @unico.ch then it is unico, otherwise it is user
data$created_by_group <- as.factor(ifelse(data$created_by == "admin", "System", ifelse(grepl("@unico.ch", data$created_by), "Unico", "User")))
```

```{r save}
# Save the data
write.csv(data, "Data/data.csv",row.names = FALSE)
```





```{r import2}
data <- read_csv("Data/data_withclusters.csv")
```
```{r plots}
# Filter the top 10 assignment groups of number of cases
data_assignment_group_top10 <- data %>% 
  group_by(assignment_group) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  head(10)

# Filter data, where assignment group is in the top 10

# Color for another variable
data_assignment_group <- data %>% 
  filter(assignment_group %in% data_assignment_group_top10$assignment_group)

ggplot(data = data_assignment_group) +
  geom_bar(mapping = aes(x = assignment_group, fill = assignment_group))
```
We see that most Tickets is assigned to the assignment group "Service Desk". Which is the first level of support in the Unico Data AG. 

```{r}
ggplot(data = data_assignment_group) +
  geom_point(
    mapping = aes(x = openedToClosed, y = reassignment_count, color = cluster)) +
  geom_smooth(mapping = aes(x = openedToClosed, y = reassignment_count))

ggplot(data = data_assignment_group, mapping = aes(x = openedToClosed, y = reassignment_count)) +
  geom_boxplot(mapping = aes(group = cut_number(openedToClosed, 10))) +
  geom_smooth(mapping = aes(x = openedToClosed, y = reassignment_count))
```
```{r plot}
ggplot(data = data, mapping = aes(x = data$time_worked, y = data$reassignment_count)) +
  geom_point(mapping = aes(color = assignment_group, size = data$business_percentage)) +
  geom_smooth()
```

```{r}  
library(viridis)   
library(RColorBrewer)

display.brewer.all()



ggplot(data_assignment_group %>% filter(time_worked < 400000) %>% filter(reassignment_count < 5) %>% filter(business_percentage < 100) %>% filter(cluster == 1) %>% filter(assignment_group != "Service Desk 1st Level"), 
       aes(x = time_worked, 
           y = openedToClosed, 
           color = assignment_group,
           size = business_percentage)) +
  geom_point(alpha = .5) + 
  scale_color_brewer(palette = "Dark2") +
  labs(title = "Time Worked by Account and OpenedToClosed",
       y = "Opened to Closed (Hours)", x = "Time Worked (Hours)")

# Do the same plot as interactiive plot with plotly library
library(plotly)



p <- ggplot(data_assignment_group %>% filter(time_worked < 400000) %>% filter(reassignment_count < 5) %>% filter(business_percentage < 100) %>% filter(cluster == 2) %>% filter(assignment_group != "Service Desk 1st Level"), 
       aes(x = time_worked, 
           y = openedToClosed, 
           color = assignment_group,
           size = business_percentage)) +
  geom_point(alpha = .5) + 
  scale_color_brewer(palette = "Dark2") +
  labs(title = "Time Worked by Account and OpenedToClosed",
       y = "Opened to Closed (Hours)", x = "Time Worked (Hours)")

ggplotly(p)
```
## Opened To Closed by Assignment Group

We will now look at the opened to closed time by assignment group. We will use a barplot and a boxplot to visualize the data. 
First Check how the feature is distributed:
```{r,echo=FALSE}
#Let's visualize the wage columnns with and without outliers
data %>%
  plot_outlier(col="aquamarine3",diagnose_outlier(data['openedToClosed']) %>%
                 filter(outliers_ratio >= 0.5) %>%          # dplyr
                 select(variables) %>%
                 unlist())

```

### Handle outliers

Since we have already looked at the outlier-distribution above, we think it is better to use the outlierhandling

```{r,echo=FALSE}
outlier <- function(x){
  quantiles <- quantile(x, c(.05, .95))
  x[x < quantiles[1]] <- quantiles[1]
  x[x > quantiles[2]] <- quantiles[2]
  x
}   
```

In the next step, we apply the outlier function. For this, we use the map_df function. This allows us to apply a function to each element of a list or atomic vector.

```{r, echo=FALSE}

#Use function outlier for the dataset
data['openedToClosed'] <- map_df(data['openedToClosed'], outlier)

#Save to later use on 
data_outliers10 <- data
```

Let's look at the distribution of the OpenedToClosed now:

```{r, echo=FALSE}
# Let's check our dependent variable "wage"
ggplot(data_outliers10, aes(x = openedToClosed)) + 
  geom_histogram(fill="aquamarine3", color = "black") +
  labs(title = "Histogram of the wages for option 1") +
  theme(legend.position="none")
```

### Barplot and Boxplot
```{r barplot}
# Barplot of the mean of opendedToClosed by assignment group
# Order ggplot increasing by the mean of openedToClosed


ggplot(data = data_assignment_group, 
       aes(x = assignment_group, 
           y = openedToClosed, 
           fill = assignment_group)) +
  geom_bar(stat = "summary") +
  labs(title = "Mean of Opened to Closed by Assignment Group",
       y = "Mean of Opened to Closed (Hours)", x = "Assignment Group") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Same plot as Boxplot
ggplot(data = data_assignment_group, 
       aes(x = assignment_group, 
           y = openedToClosed, 
           fill = assignment_group)) +
  geom_boxplot() +
  labs(title = "Boxplot of Opened to Closed by Assignment Group",
       y = "Opened to Closed (Hours)", x = "Assignment Group") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
```{r}
library(dplyr)
library(tidyverse)
#transform the data to tibble

data <- as_tibble(data)
group <- data %>%
  group_by(assignment_group) %>%
  summarize(
    totalTime = mean(openedToClosed, na.rm = TRUE),
    timeWorked = mean(time_worked, na.rm = TRUE),
    n = n()
  )

# add labs to code
ggplot(group, aes(totalTime, fct_reorder(assignment_group, totalTime))) +
  geom_point() +
  labs(title = "Total Time by Assignment Group",
       y = "Assignment Group", x = "Total Time (Hours)")
```
## Time Plots

### Overview
```{r}
data %>%
  ggplot(aes(opened)) +
  geom_freqpoly(binwidth = 86400) # 86400 seconds = 1 day
```
```{r}
data %>%
  filter(opened > "2023-01-01") %>%
  ggplot() +
  geom_freqpoly(aes(x = opened, color = "Opened"), binwidth = 86400) +
  geom_freqpoly(aes(x = closed, color = "Closed"), binwidth = 86400) +
  scale_color_manual(values = c("Opened" = "blue", "Closed" = "red")) +
  labs(title = "Frequency of Opened and Closed Cases Over Time",
       x = "Date",
       y = "Frequency",
       color = "Case Status") +
  coord_cartesian(ylim = c(0, 100))

```

### During the week
```{r}
library(tidyverse)
library(lubridate)

data %>%
  mutate(wday = lubridate::wday(opened, label = TRUE, abbr = FALSE)) %>%
  ggplot(aes(x = wday)) +
    geom_bar()
```

