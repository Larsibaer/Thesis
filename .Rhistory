write.csv(data, "Data/data.csv",row.names = FALSE)
rm(list=ls())
setwd("C:/Thesis")
#Filter: https://kiwi.unico.ch/now/nav/ui/classic/params/target/sys_history_line_list.do%3Fsysparm_query%3Dset.tableSTARTSWITHsn_cus%255Efield%253Dstate%255EORfield%253Dassignment_group%255EORfield%253Dassigned_to%255Eset.initial_valuesLIKE%253Cu_case_type%253ETrouble%253C%252Fu_case_type%253E%255EORDERBYset%26sysparm_first_row%3D1%26sysparm_view%3D
history_data <- read_csv("Data/sys_history_line.csv", locale = locale(encoding = "UTF-8"))
data <- history_data
data$set <- trimws(gsub("Case:", " ", data$set))
data$update_time <- as.POSIXct(strptime(data$update_time, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data_all <- read_csv("Data/data.csv", locale = locale(encoding = "UTF-8"))
#Merge opened and closed from data_new to data by number
data_all <- select(data_all, number, account, opened, closed, openedToClosed)
data <- merge(data, data_all, by.x = "set", by.y = "number", all.x = FALSE)
#Merge opened and closed from data_new to data by number
data_all <- select(data_all, number, account, opened, closed, openedToClosed)
data <- merge(data, data_all, by.x = "set", by.y = "number", all.x = FALSE)
# Add Column for the time difference between opened_at and update_time
data <- data %>%
mutate(time_diff_opened = as.numeric(update_time - opened))
data_state <- data %>%
filter(field == "state") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_state = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
data_assignment_group <- data %>%
filter(field == "assignment_group") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assignment_group = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
data_assigned_to <- data %>%
filter(field == "assigned_to") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assigned_to = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
# compute the precentage of time of time_diff_previous_state and the openedtoClosed
data_state <- data_state %>%
mutate(time_diff_previous_state_prec = time_diff_previous_state/openedToClosed)
View(data_state)
rm(list=ls())
setwd("C:/Thesis")
#Filter: https://kiwi.unico.ch/now/nav/ui/classic/params/target/sys_history_line_list.do%3Fsysparm_query%3Dset.tableSTARTSWITHsn_cus%255Efield%253Dstate%255EORfield%253Dassignment_group%255EORfield%253Dassigned_to%255Eset.initial_valuesLIKE%253Cu_case_type%253ETrouble%253C%252Fu_case_type%253E%255EORDERBYset%26sysparm_first_row%3D1%26sysparm_view%3D
history_data <- read_csv("Data/sys_history_line.csv", locale = locale(encoding = "UTF-8"))
data <- history_data
data$set <- trimws(gsub("Case:", " ", data$set))
data$update_time <- as.POSIXct(strptime(data$update_time, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data_all <- read_csv("Data/data.csv", locale = locale(encoding = "UTF-8"))
#Merge opened and closed from data_new to data by number
data_all <- select(data_all, number, account, opened, closed, openedToClosed)
data <- merge(data, data_all, by.x = "set", by.y = "number", all.x = FALSE)
# Add Column for the time difference between opened_at and update_time
data <- data %>%
mutate(time_diff_opened = as.numeric(update_time - opened))
data_state <- data %>%
filter(field == "state") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_state = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
data_assignment_group <- data %>%
filter(field == "assignment_group") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assignment_group = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
data_assigned_to <- data %>%
filter(field == "assigned_to") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assigned_to = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
# compute the precentage of time of time_diff_previous_state and the openedtoClosed
data_state <- data_state %>%
mutate(time_diff_previous_state_prec = time_diff_previous_state/openedToClosed)
View(data_state)
# Save the data
write.csv(data, "Data/data.csv",row.names = FALSE)
rm(list=ls())
setwd("C:/Thesis")
#Filter: https://kiwi.unico.ch/now/nav/ui/classic/params/target/sys_history_line_list.do%3Fsysparm_query%3Dset.tableSTARTSWITHsn_cus%255Efield%253Dstate%255EORfield%253Dassignment_group%255EORfield%253Dassigned_to%255Eset.initial_valuesLIKE%253Cu_case_type%253ETrouble%253C%252Fu_case_type%253E%255EORDERBYset%26sysparm_first_row%3D1%26sysparm_view%3D
history_data <- read_csv("Data/sys_history_line.csv", locale = locale(encoding = "UTF-8"))
data <- history_data
data$set <- trimws(gsub("Case:", " ", data$set))
data$update_time <- as.POSIXct(strptime(data$update_time, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data_all <- read_csv("Data/data.csv", locale = locale(encoding = "UTF-8"))
#Merge opened and closed from data_new to data by number
data_all <- select(data_all, number, account, opened, closed, openedToClosed)
data <- merge(data, data_all, by.x = "set", by.y = "number", all.x = FALSE)
# Add Column for the time difference between opened_at and update_time
data <- data %>%
mutate(time_diff_opened = as.numeric(update_time - opened))
data_state <- data %>%
filter(field == "state") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_state = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
data_assignment_group <- data %>%
filter(field == "assignment_group") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assignment_group = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
data_assigned_to <- data %>%
filter(field == "assigned_to") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assigned_to = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
# compute the precentage of time of time_diff_previous_state and the openedtoClosed
data_state <- data_state %>%
mutate(time_diff_previous_state_prec = time_diff_previous_state/openedToClosed)
View(data_state)
View(data_state)
# compute the precentage of time of time_diff_previous_state and the openedtoClosed
data_state <- data_state %>%
mutate(time_diff_previous_state_prec = time_diff_previous_state/openedToClosed)
rm(list=ls())
setwd("C:/Thesis")
#Filter: https://kiwi.unico.ch/now/nav/ui/classic/params/target/sys_history_line_list.do%3Fsysparm_query%3Dset.tableSTARTSWITHsn_cus%255Efield%253Dstate%255EORfield%253Dassignment_group%255EORfield%253Dassigned_to%255Eset.initial_valuesLIKE%253Cu_case_type%253ETrouble%253C%252Fu_case_type%253E%255EORDERBYset%26sysparm_first_row%3D1%26sysparm_view%3D
history_data <- read_csv("Data/sys_history_line.csv", locale = locale(encoding = "UTF-8"))
data <- history_data
data$set <- trimws(gsub("Case:", " ", data$set))
data$update_time <- as.POSIXct(strptime(data$update_time, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data_all <- read_csv("Data/data.csv", locale = locale(encoding = "UTF-8"))
#Merge opened and closed from data_new to data by number
data_all <- select(data_all, number, account, opened, closed, openedToClosed)
data <- merge(data, data_all, by.x = "set", by.y = "number", all.x = FALSE)
# Add Column for the time difference between opened_at and update_time
data <- data %>%
mutate(time_diff_opened = as.numeric(update_time - opened))
#Merge opened and closed from data_new to data by number
data_all <- select(data_all, number, account, opened, closed, openedToClosed)
rm(list=ls())
data_all <- read_csv("Data/data.csv", locale = locale(encoding = "UTF-8"))
knitr::opts_chunk$set(echo = TRUE)
# We start by installing the necessary libraries. Make sure to uncomment and run
# only the libraries which you haven't installed already.
#install.packages("DescTools")
#install.packages("xgboost")
#install.packages("caret")
#install.packages("dplyr")
#install.packages("tidyverse")
#install.packages("mltools")
#install.packages("reshape2")
#install.packages("data.table")
#install.packages("pracma")
#install.packages("rsample")
# install.packages("PRROC")
# install.packages("e1071")
# install.packages("dlookr")
# install.packages("pROC")
# install.packages("ROCR")
# install.packages("nnet")
library(DescTools)
library(xgboost)
library(caret)
library(dplyr)
library(tidyverse)
library(mltools)
library(reshape2)
library(data.table)
library(pracma)
library(rsample)
library(PRROC)
library(e1071)
library(dlookr)
library(pROC)
library(ROCR)
library(nnet)
library(ggplot2)
#library POSIXct
library(lubridate)
options(scipen=999)
## Import data
# We set the working directory and we call the data that we are going to use. Please import the csv file.
rm(list=ls())
set.seed(7)
setwd("C:/Thesis")
#read json file
cases_data <- read_csv("Data/sn_customerservice_case.csv", locale = locale(encoding = "UTF-8"))
data <- cases_data # We make a copy from the original dataset and work on the copy
# show the column comments
cases_data %>%
select(comments_and_work_notes) %>%
head(10)
# Split the comments column into multiple columns. Split all the comments by the character "mm-dd-YYY HH:MM:SS - " and create a new column for each part of the comment
# Example string
# Split the string using a regex pattern
# The pattern \d{2}-\d{2}-\d{4} \d{2}:\d{2}:\d{2} - matches the date and time format
split_text <- strsplit(cases_data$comments_and_work_notes[202], split = "\\d{2}-\\d{2}-\\d{4} \\d{2}:\\d{2}:\\d{2} -", perl = TRUE)
# View the result
print(cases_data$comments_and_work_notes[202])
print(split_text)
print(cases_data$number[202])
data <- select(cases_data, number = number, case = short_description, description = description, case_type = u_case_type, first_response_time = first_response_time, closed = closed_at, opened = opened_at, account = account, created_by = sys_created_by, business_service = business_service, assigned_to = assigned_to, assignment_group = assignment_group, auto_close = auto_close, time_worked = u_total_time_worked, reassignment_count = reassignment_count, impact = impact, priority = priority, urgency = urgency, comments = comments_and_work_notes, case_cause = u_case_cause, cause = cause, close_notes = close_notes, resolution_code = resolution_code)
# Filter between dates and removing rows who are not closed
data <- data %>%
filter(Year(strptime(data$opened, "%d-%m-%Y %H:%M:%S", tz="UTC")) <= Year("2024-02-01")) %>%
filter(Year(strptime(data$opened, "%d-%m-%Y %H:%M:%S", tz="UTC")) >= Year("2020-01-01")) %>%
filter(!is.na(closed))
# Transforming the type of the variables
data$opened <- as.POSIXct(strptime(data$opened, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data$closed <- as.POSIXct(strptime(data$closed, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data$first_response_time <- as.POSIXct(strptime(data$first_response_time, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data$auto_close <- as.factor(data$auto_close)
data$reassignment_count <- as.numeric(data$reassignment_count)
data$impact <- as.factor(data$impact)
data$priority <- as.factor(data$priority)
data$urgency <- as.factor(data$urgency)
data$case_cause <- as.factor(data$case_cause)
data$resolution_code <- as.factor(data$resolution_code)
data$assignment_group <- as.factor(data$assignment_group)
data$assigned_to <- as.factor(data$assigned_to)
data$created_by <- as.factor(data$created_by)
data$business_service <- as.factor(data$business_service)
data$case_type <- as.factor(data$case_type)
data$account <- as.factor(data$account)
data$openedToClosed <- as.numeric(difftime(data$closed, data$opened, units = "hours"))
# add column created by cleaned. When cretad_by is admin, then it is system, when created_by ends witch @unico.ch then it is unico, otherwise it is user
data$created_by_group <- as.factor(ifelse(data$created_by == "admin", "System", ifelse(grepl("@unico.ch", data$created_by), "Unico", "User")))
# merg data sets
sla_data_clean <- read_csv("Data/task_sla.csv")
# Remove all rows, where sla_data£status is Cancelled
# sla_data <- sla_data %>%
#   filter(stage != "Cancelled")
# Merge data and sla_data, where the number and closed of data is the same as task and stop time of sla_data
sla_data <- select(sla_data_clean, task = task, business_percentage = business_percentage, sla_has_breached = has_breached, end_time = task.closed_at)
#remove duplicates of sla_data$task
sla_data <- sla_data %>%
distinct(task, .keep_all = TRUE)
sla_data$end_time <- as.POSIXct(strptime(sla_data$end_time, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data <- merge(x = data, y = sla_data,
by.x = c('number', 'closed'),
by.y = c('task', 'end_time'),
all.x = TRUE)
data$business_percentage <- as.numeric(data$business_percentage)
data$sla_has_breached <- as.factor(data$sla_has_breached)
# Take specific STRUCTUREED columns how are interesting and remove all NA's
data <- na.omit(select(data, number, account, created_by_group, business_service, assignment_group, auto_close, impact, priority, urgency, sla_has_breached, case_cause, resolution_code, reassignment_count, time_worked, opened, closed, openedToClosed, business_percentage))
#Remove all rows, where account, Busienss Service and created_by is less than 100 time in the dataset
data <- data %>% group_by(account) %>% filter(n() > 100)
data <- data %>% group_by(business_service) %>% filter(n() > 100)
data <- data %>% group_by(assignment_group) %>% filter(n() > 20)
#Verzicht auf Case Type, da ich sowieso nur Troubles anschaue
#data <- data %>% filter(case_type == 'Trouble')
outlier <- function(x){
quantiles <- quantile(x, c(.05, .95))
x[x < quantiles[1]] <- quantiles[1]
x[x > quantiles[2]] <- quantiles[2]
x
}
#Use function outlier for the dataset
# data['reassignment_count'] <- map_df(data['reassignment_count'], outlier)
# data['time_worked'] <- map_df(data['time_worked'], outlier)
# data['openedToClosed'] <- map_df(data['openedToClosed'], outlier)
# data['business_percentage'] <- map_df(data['business_percentage'], outlier)
# data_new <- merge(data, cases_data[c('sys_id','number','description', 'cause', 'close_notes')], by = "number", all.x = FALSE)
data <- merge(data, cases_data[c('number','description', 'cause', 'close_notes')], by = "number", all.x = FALSE)
# Save the data
write.csv(data, "Data/data.csv",row.names = FALSE)
rm(list=ls())
data_all <- read_csv("Data/data.csv", locale = locale(encoding = "UTF-8"))
setwd("C:/Thesis")
#Filter: https://kiwi.unico.ch/now/nav/ui/classic/params/target/sys_history_line_list.do%3Fsysparm_query%3Dset.tableSTARTSWITHsn_cus%255Efield%253Dstate%255EORfield%253Dassignment_group%255EORfield%253Dassigned_to%255Eset.initial_valuesLIKE%253Cu_case_type%253ETrouble%253C%252Fu_case_type%253E%255EORDERBYset%26sysparm_first_row%3D1%26sysparm_view%3D
history_data <- read_csv("Data/sys_history_line.csv", locale = locale(encoding = "UTF-8"))
data <- history_data
data$set <- trimws(gsub("Case:", " ", data$set))
data$update_time <- as.POSIXct(strptime(data$update_time, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data_all <- read_csv("Data/data.csv", locale = locale(encoding = "UTF-8"))
#Merge opened and closed from data_new to data by number
data_all <- select(data_all, number, account, opened, closed, openedToClosed)
data <- merge(data, data_all, by.x = "set", by.y = "number", all.x = FALSE)
# Add Column for the time difference between opened_at and update_time
data <- data %>%
mutate(time_diff_opened = as.numeric(update_time - opened))
data_state <- data %>%
filter(field == "state") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_state = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
data_assignment_group <- data %>%
filter(field == "assignment_group") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assignment_group = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
data_assigned_to <- data %>%
filter(field == "assigned_to") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assigned_to = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
# compute the precentage of time of time_diff_previous_state and the openedtoClosed
data_state <- data_state %>%
mutate(time_diff_previous_state_prec = time_diff_previous_state/openedToClosed)
View(data_state)
# compute the precentage of time of time_diff_previous_state and the openedtoClosed
data_state <- data_state %>%
mutate(time_diff_previous_state_prec = time_diff_previous_state/openedToClosed*100)
View(data_state)
# compute the precentage of time of time_diff_previous_state and the sum of time_diff_previous_state
data_state <- data_state %>%
group_by(set) %>%
summarise(time_diff_previous_state_sum = sum(time_diff_previous_state, na.rm = TRUE)) %>%
mutate(time_diff_previous_state_prec = time_diff_previous_state/time_diff_previous_state_sum*100) %>%
ungroup()
rm(list=ls())
setwd("C:/Thesis")
#Filter: https://kiwi.unico.ch/now/nav/ui/classic/params/target/sys_history_line_list.do%3Fsysparm_query%3Dset.tableSTARTSWITHsn_cus%255Efield%253Dstate%255EORfield%253Dassignment_group%255EORfield%253Dassigned_to%255Eset.initial_valuesLIKE%253Cu_case_type%253ETrouble%253C%252Fu_case_type%253E%255EORDERBYset%26sysparm_first_row%3D1%26sysparm_view%3D
history_data <- read_csv("Data/sys_history_line.csv", locale = locale(encoding = "UTF-8"))
data <- history_data
data$set <- trimws(gsub("Case:", " ", data$set))
data$update_time <- as.POSIXct(strptime(data$update_time, "%d-%m-%Y %H:%M:%S", tz="UTC"))
data_all <- read_csv("Data/data.csv", locale = locale(encoding = "UTF-8"))
#Merge opened and closed from data_new to data by number
data_all <- select(data_all, number, account, opened, closed, openedToClosed)
data <- merge(data, data_all, by.x = "set", by.y = "number", all.x = FALSE)
# Add Column for the time difference between opened_at and update_time
data <- data %>%
mutate(time_diff_opened = as.numeric(update_time - opened))
data_state <- data %>%
filter(field == "state") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_state = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
data_assignment_group <- data %>%
filter(field == "assignment_group") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assignment_group = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
data_assigned_to <- data %>%
filter(field == "assigned_to") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assigned_to = (as.numeric(update_time - lag(update_time))/3600)) %>%
ungroup()
# compute the precentage of time of time_diff_previous_state and the sum of time_diff_previous_state
data_state2 <- data_state %>%
group_by(set) %>%
summarise(time_diff_previous_state_sum = sum(time_diff_previous_state, na.rm = TRUE)) %>%
mutate(time_diff_previous_state_prec = time_diff_previous_state/time_diff_previous_state_sum*100) %>%
ungroup()
# compute the precentage of time of time_diff_previous_state and the sum of time_diff_previous_state
data_state2 <- data_state %>%
group_by(set) %>%
mutate(time_diff_previous_state = time_diff_previous_state/sum(time_diff_previous_state)) %>%
ungroup()
View(data_state2)
# compute the precentage of time_diff_previous_state and the sum of time_diff_previous_state for each set
data_state2 <- data_state %>%
group_by(set) %>%
mutate(time_diff_previous_state = time_diff_previous_state/sum(time_diff_previous_state)) %>%
ungroup()
View(data_state2)
# compute the precentage of time_diff_previous_state and the sum of time_diff_previous_state for each set
data_state2 <- data_state %>%
group_by(set) %>%
mutate(time_diff_previous_state2 = time_diff_previous_state/sum(time_diff_previous_state)) %>%
ungroup()
View(data_state2)
# compute the precentage of time_diff_previous_state and the sum of time_diff_previous_state for each set
data_state2 <- data_state %>%
group_by(set) %>%
mutate(time_diff_previous_state2 = time_diff_previous_state/2) %>%
ungroup()
View(data_state2)
# compute the precentage of time_diff_previous_state and the sum of time_diff_previous_state for each set
data_state2 <- data_state %>%
group_by(set) %>%
mutate(time_diff_previous_state2 = time_diff_previous_state/sum(time_diff_previous_state)) %>%
ungroup()
View(data_state2)
View(data_state2)
# compute for each set the precentage of time_diff_previous_state and the sum of time_diff_previous_state
data_state2 <- data_state %>%
group_by(set) %>%
mutate(time_diff_previous_state = time_diff_previous_state/sum(time_diff_previous_state)) %>%
ungroup()
View(data_state2)
data_state2 <- data_state %>%
group_by(set)
View(data_state2)
data_state2 <- data_state %>%
group_by(set) %>%
data_state2$time_diff_previous_state_prec <- time_diff_previous_state/sum(time_diff_previous_state)
data_state2 <- data_state %>%
group_by(set) %>%
mutate(sum_time_diff = sum(time_diff_previous_state, na.rm = TRUE)) %>%
ungroup()
View(data_state2)
data_state2 <- data_state %>%
group_by(set) %>%
mutate(sum_time_diff = sum(time_diff_previous_state, na.rm = TRUE)) %>%
mutate(percentage_time_diff = time_diff_previous_state / sum_time_diff * 100) %>%
ungroup()
View(data_state2)
data_state <- data_state %>%
group_by(set) %>%
mutate(sum_time_diff = sum(time_diff_previous_state, na.rm = TRUE)) %>%
mutate(percentage_time_diff = time_diff_previous_state / sum_time_diff * 100) %>%
ungroup()
View(data)
View(data_state)
data_state <- data %>%
filter(field == "state") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_state = (as.numeric(update_time - lag(update_time))/3600)) %>%
mutate(sum_time_diff_state = sum(time_diff_previous_state, na.rm = TRUE)) %>%
mutate(percentage_time_diff_state = time_diff_previous_state / sum_time_diff * 100) %>%
ungroup()
data_state <- data %>%
filter(field == "state") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_state = (as.numeric(update_time - lag(update_time))/3600)) %>%
mutate(sum_time_diff_state = sum(time_diff_previous_state, na.rm = TRUE)) %>%
mutate(percentage_time_diff_state = time_diff_previous_state / sum_time_diff_state * 100) %>%
ungroup()
data_assignment_group <- data %>%
filter(field == "assignment_group") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assignment_group = (as.numeric(update_time - lag(update_time))/3600)) %>%
mutate(sum_time_diff_assignment_group = sum(time_diff_previous_state, na.rm = TRUE)) %>%
mutate(percentage_time_diff_assignment_group = time_diff_previous_state / sum_time_diff_assignment_group * 100) %>%
ungroup()
data_assigned_to <- data %>%
filter(field == "assigned_to") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assigned_to = (as.numeric(update_time - lag(update_time))/3600)) %>%
mutate(sum_time_diff_assigned_to = sum(time_diff_previous_state, na.rm = TRUE)) %>%
mutate(percentage_time_diff_assigned_to = time_diff_previous_state / sum_time_diff_assigned_to * 100) %>%
ungroup()
data_state <- data %>%
filter(field == "state") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_state = (as.numeric(update_time - lag(update_time))/3600)) %>%
mutate(sum_time_diff_state = sum(time_diff_previous_state, na.rm = TRUE)) %>%
mutate(percentage_time_diff_state = time_diff_previous_state / sum_time_diff_state * 100) %>%
ungroup()
data_assignment_group <- data %>%
filter(field == "assignment_group") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assignment_group = (as.numeric(update_time - lag(update_time))/3600)) %>%
mutate(sum_time_diff_assignment_group = sum(time_diff_previous_state, na.rm = TRUE)) %>%
mutate(percentage_time_diff_assignment_group = time_diff_previous_assignment_group / sum_time_diff_assignment_group * 100) %>%
ungroup()
data_state <- data %>%
filter(field == "state") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_state = (as.numeric(update_time - lag(update_time))/3600)) %>%
mutate(sum_time_diff_state = sum(time_diff_previous_state, na.rm = TRUE)) %>%
mutate(percentage_time_diff_state = time_diff_previous_state / sum_time_diff_state * 100) %>%
ungroup()
data_assignment_group <- data %>%
filter(field == "assignment_group") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assignment_group = (as.numeric(update_time - lag(update_time))/3600)) %>%
mutate(sum_time_diff_assignment_group = sum(time_diff_previous_assignment_group, na.rm = TRUE)) %>%
mutate(percentage_time_diff_assignment_group = time_diff_previous_assignment_group / sum_time_diff_assignment_group * 100) %>%
ungroup()
data_assigned_to <- data %>%
filter(field == "assigned_to") %>%
group_by(set) %>%
arrange(update_time) %>%
mutate(time_diff_previous_assigned_to = (as.numeric(update_time - lag(update_time))/3600)) %>%
mutate(sum_time_diff_assigned_to = sum(time_diff_previous_assigned_to, na.rm = TRUE)) %>%
mutate(percentage_time_diff_assigned_to = time_diff_previous_assigned_to / sum_time_diff_assigned_to * 100) %>%
ungroup()
View(data_assignment_group)
#Merge percentage_time_diff_assigned_to to data by set, field and update_time
data2 <- merge(data, data_assigned_to, by = c("set", "field", "update_time"), all.x = FALSE)
View(data2)
left_join(data_assigned_to[, c("set", "new_column3")], by = c("set", "field", "update_time"))
left_join(data_state[, c("set", "percentage_time_diff_state")], by = c("set", "field", "update_time") %>%
data2 <- data %>%
left_join(data_state[, c("set", "percentage_time_diff_state")], by = c("set", "field", "update_time")) %>%
left_join(data_assignment_group[, c("set", "percentage_time_diff_assignment_group")], by = c("set", "field", "update_time")) %>%
left_join(data_assigned_to[, c("set", "percentage_time_diff_assigned_to")], by = c("set", "field", "update_time"))
data2 <- data %>%
data2 <- data %>%
left_join(data_state[, c("set", "percentage_time_diff_state")], by = "set") %>%
left_join(data_assignment_group[, c("set", "percentage_time_diff_assignment_group")], by = "set") %>%
left_join(data_assigned_to[, c("set", "percentage_time_diff_assigned_to")], by = "set")
View(data_state)
# Prepare the subset dataframes by selecting only the necessary columns
data_state_summary <- data_state %>%
select(set, sum_time_diff_state, percentage_time_diff_state) %>%
distinct()  # Assuming you want to remove duplicates
data_assignment_group_summary <- data_assignment_group %>%
select(set, sum_time_diff_assignment_group, percentage_time_diff_assignment_group) %>%
distinct()  # Assuming you want to remove duplicates
data_assigned_to_summary <- data_assigned_to %>%
select(set, sum_time_diff_assigned_to, percentage_time_diff_assigned_to) %>%
distinct()  # Assuming you want to remove duplicates
# Join these summaries back to the main dataframe
data2 <- data %>%
left_join(data_state_summary, by = "set") %>%
left_join(data_assignment_group_summary, by = "set") %>%
left_join(data_assigned_to_summary, by = "set")
View(data_state_summary)
