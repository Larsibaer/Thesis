{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# your code that triggers the warning goes here\n",
    "\n",
    "pd.options.mode.chained_assignment = 'warn'  # set it back to the default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Specifying data types for columns while reading a CSV file\n",
    "dtype_dict = {\n",
    "    \"number\": \"str\",\n",
    "    \"closed\": \"str\", \n",
    "    \"case\": \"str\",\n",
    "    \"description\": \"str\",\n",
    "    \"case_type\": \"category\",\n",
    "    \"due_date\": \"str\", \n",
    "    \"first_response_time\": \"str\", \n",
    "    \"opened\": \"str\",  \n",
    "    \"account\": \"category\",\n",
    "    \"contact\": \"category\",\n",
    "    \"created_by\": \"category\",\n",
    "    \"business_service\": \"category\",\n",
    "    \"business_service_activity\": \"category\",\n",
    "    \"assigned_to\": \"category\",\n",
    "    \"assignment_group\": \"category\",\n",
    "    \"auto_close\": \"category\",\n",
    "    \"time_worked\": \"float\",\n",
    "    \"reassignment_count\": \"int\",\n",
    "    \"impact\": \"category\",\n",
    "    \"priority\": \"category\",\n",
    "    \"urgency\": \"category\",\n",
    "    \"escalation\": \"category\",\n",
    "    \"comments\": \"str\",\n",
    "    \"case_cause\": \"category\",\n",
    "    \"cause\": \"str\",\n",
    "    \"close_notes\": \"str\",\n",
    "    \"resolution_code\": \"category\",\n",
    "    \"problem\": \"category\",\n",
    "    \"business_percentage\": \"float\",\n",
    "    \"sla_has_breached\": \"category\",\n",
    "    \"duration\": \"float\",\n",
    "    \"openedToClosed\": \"float\",\n",
    "    \"created_by_group\": \"category\"\n",
    "}\n",
    "\n",
    "# read csv file into dataframe\n",
    "df = pd.read_csv('Data/data_new.csv', dtype = dtype_dict)\n",
    "\n",
    "# print shape of dataframe \n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "# profile.to_notebook_iframe()\n",
    "# profile.to_file(f\"./html/Profiling Report Overall.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"business_service\"].value_counts() / len(df) * 100).head(10).plot(kind = \"barh\")\n",
    "# add procent value to bar\n",
    "for index, value in enumerate((df[\"business_service\"].value_counts() / len(df) * 100).head(10)):\n",
    "    plt.text(value, index, str(round(value, 2)) + '%')\n",
    "plt.title(\"Top 10 Business Service\")\n",
    "plt.xlabel(\"Prozent\")\n",
    "plt.ylabel(\"Business Service\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displau Short Description (case), Description, Cause and close_notes\n",
    "df_text = df[['description', 'cause', 'close_notes']]\n",
    "\n",
    "# preprocess df_text columns \n",
    "\n",
    "display(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_captions(data, column):\n",
    "    data[column] = data[column].apply(lambda x: x.replace('\\n', ' '))\n",
    "    data[column] = data[column].apply(lambda x: x.replace('-', ' '))\n",
    "    data[column] = data[column].apply(lambda x: x.lower())\n",
    "    data[column] = data[column].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]', ' ', x))\n",
    "    return data[column]\n",
    "\n",
    "# change datatype of columns to string\n",
    "df_text['description'] = df_text['description'].astype(str).copy()\n",
    "df_text['cause'] = df_text['cause'].astype(str).copy()\n",
    "df_text['close_notes'] = df_text['close_notes'].astype(str).copy()\n",
    "\n",
    "df_text['description'] = process_captions(df_text, 'description').copy()\n",
    "df_text['cause'] = process_captions(df_text, 'cause').copy()\n",
    "df_text['close_notes'] = process_captions(df_text, 'close_notes').copy()\n",
    "\n",
    "display(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "stopwords = requests.get(\"https://raw.githubusercontent.com/stopwords-iso/stopwords-de/master/stopwords-de.txt\").text.split(\"\\n\")\n",
    "# Add common words to stopwords\n",
    "stopwords.extend([\"nan\", \"frau\", \"herr\", \"ch\", \"bitte\", \"st\"])\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create empty df to store the top 50 words for each column\n",
    "top_50_words = pd.DataFrame()\n",
    "\n",
    "for column in df_text.columns:\n",
    "    tfidf = TfidfVectorizer(stop_words=stopwords)\n",
    "    text = tfidf.fit_transform(df_text[column])\n",
    "\n",
    "    VectorizedText = pd.DataFrame(text.toarray(), columns=tfidf.get_feature_names_out())\n",
    "    # Add to all columns the column name\n",
    "    VectorizedText.columns = [column + \"_\" + col for col in VectorizedText.columns]\n",
    "    column_sums = VectorizedText.sum(axis=0).sort_values(ascending=False)\n",
    "\n",
    "    # Select the names of the top 50 columns with the highest sums\n",
    "    top_50_columns = column_sums.head(25).index\n",
    "    top_50_words[column] = top_50_columns\n",
    "\n",
    "    # Subset the original DataFrame to keep only these top 50 columns\n",
    "    minimized_df = VectorizedText[top_50_columns]\n",
    "\n",
    "    # save minimized_df to csv\n",
    "    minimized_df.to_csv('Data/VectorizedText_' + column + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
